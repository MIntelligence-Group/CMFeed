Multimodal Affective Feedback Synthesis for Text and Image Data
================================================

Implementation for the paper (submitted to ICASSP 2022). <br>
**[Multimodal Affective Feedback Synthesis for Text and Image Data][1]**<br>
[Puneet Kumar](https://puneet-kr.github.io/), [Gaurav Bhatt](http://deeplearn-ai.com/), Omkar Ingle, Daksh Goyal and [Balasubramanian Raman](http://faculty.iitr.ac.in/~balarfma/)  

### Note: The code files are currently private. They will be shared soon after the paper is accepted for publication.

Dataset Access
--------------
[ToDo] Access to the ‘... dataset’ can be obtained by through [`Access Form - IIT-R ... Dataset.pdf`][6]. The dataset is compiled by ... at Machine Intelligence Lab, 
IIT Roorkee under the supervision of Prof. Balasubramanian Raman. It contains  images, text and comments. 

[1]: https://2022.ieeeicassp.org/
[2]:https://github.com/MIntelligence-Group/MMFeed/blob/main/Access%20Form%20-%20IIT-R%20TIER%20Dataset.pdf 
