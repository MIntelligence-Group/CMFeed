{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define 'EPOCHS' (total epochs) and 'EP_INT' (interval epochs) and then run from the starting..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchtext import  vocab,data\n",
    "from torchtext.datasets import TranslationDataset, Multi30k\n",
    "from torchtext.data import Field, BucketIterator, TabularDataset\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import os, csv, sys, random, re, time, math, spacy, nltk\n",
    "\n",
    "from PIL import Image\n",
    "from numpy.random import RandomState\n",
    "from tensorboardX import SummaryWriter\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "#Define the logger\n",
    "#log_writer_train = SummaryWriter('TBlogs/train/')\n",
    "#log_writer_val = SummaryWriter('TBlogs/val/')\n",
    "#log_writer_test = SummaryWriter('TBlogs/test/')\n",
    "\n",
    "log_writer = SummaryWriter('TBlogs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5     # Total epochs to train for\n",
    "EP_INT = 1     # In the intervals of 'EP_INT' epochs\n",
    "CLIP = 1\n",
    "\n",
    "NF=1000        # For ResNet/VGG Feature Extraction\n",
    "#NF = 36*2048  # For Faster RCNN Feature Extraction using Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv(r\"train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>trg</th>\n",
       "      <th>img_path</th>\n",
       "      <th>img_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>video a bizarre conspiracy theory has surged i...</td>\n",
       "      <td>i take news with a pinch of salt so should eve...</td>\n",
       "      <td>/home/puneet/code/Multimodal Feedback/data/781...</td>\n",
       "      <td>7817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of the army which is increasingly dependent on...</td>\n",
       "      <td>honestly i never thought to earn as much as ha...</td>\n",
       "      <td>/home/puneet/code/Multimodal Feedback/data/381...</td>\n",
       "      <td>3817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>however on thursday he admitted that he had re...</td>\n",
       "      <td>but he attacked so much poland accused defamed...</td>\n",
       "      <td>/home/puneet/code/Multimodal Feedback/data/130...</td>\n",
       "      <td>1306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the pentagon said thursday that the us militar...</td>\n",
       "      <td>great news</td>\n",
       "      <td>/home/puneet/code/Multimodal Feedback/data/651...</td>\n",
       "      <td>6514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>washington pressure is growing among president...</td>\n",
       "      <td>more good news please</td>\n",
       "      <td>/home/puneet/code/Multimodal Feedback/data/230...</td>\n",
       "      <td>2309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58336</th>\n",
       "      <td>kabul afghanistan the taliban ambushed a peace...</td>\n",
       "      <td>i always for the of reeducation no hope= misle...</td>\n",
       "      <td>/home/puneet/code/Multimodal Feedback/data/669...</td>\n",
       "      <td>6697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58337</th>\n",
       "      <td>file photo the olympic rings are illuminated i...</td>\n",
       "      <td>the crazy just never seems to stop in florida ...</td>\n",
       "      <td>/home/puneet/code/Multimodal Feedback/data/541...</td>\n",
       "      <td>5417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58338</th>\n",
       "      <td>saudi arabia has sentenced five people to deat...</td>\n",
       "      <td>five lives to save face for the prince</td>\n",
       "      <td>/home/puneet/code/Multimodal Feedback/data/627...</td>\n",
       "      <td>6271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58339</th>\n",
       "      <td>acting manatee county administrator dr scott h...</td>\n",
       "      <td>floridas republican governors have been availa...</td>\n",
       "      <td>/home/puneet/code/Multimodal Feedback/data/935...</td>\n",
       "      <td>9358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58340</th>\n",
       "      <td>matamoros mexico under a canopy on the edge of...</td>\n",
       "      <td>stop spreading propagandathere are no doctors ...</td>\n",
       "      <td>/home/puneet/code/Multimodal Feedback/data/622...</td>\n",
       "      <td>6220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58341 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     src  \\\n",
       "0      video a bizarre conspiracy theory has surged i...   \n",
       "1      of the army which is increasingly dependent on...   \n",
       "2      however on thursday he admitted that he had re...   \n",
       "3      the pentagon said thursday that the us militar...   \n",
       "4      washington pressure is growing among president...   \n",
       "...                                                  ...   \n",
       "58336  kabul afghanistan the taliban ambushed a peace...   \n",
       "58337  file photo the olympic rings are illuminated i...   \n",
       "58338  saudi arabia has sentenced five people to deat...   \n",
       "58339  acting manatee county administrator dr scott h...   \n",
       "58340  matamoros mexico under a canopy on the edge of...   \n",
       "\n",
       "                                                     trg  \\\n",
       "0      i take news with a pinch of salt so should eve...   \n",
       "1      honestly i never thought to earn as much as ha...   \n",
       "2      but he attacked so much poland accused defamed...   \n",
       "3                                             great news   \n",
       "4                                  more good news please   \n",
       "...                                                  ...   \n",
       "58336  i always for the of reeducation no hope= misle...   \n",
       "58337  the crazy just never seems to stop in florida ...   \n",
       "58338             five lives to save face for the prince   \n",
       "58339  floridas republican governors have been availa...   \n",
       "58340  stop spreading propagandathere are no doctors ...   \n",
       "\n",
       "                                                img_path  img_id  \n",
       "0      /home/puneet/code/Multimodal Feedback/data/781...    7817  \n",
       "1      /home/puneet/code/Multimodal Feedback/data/381...    3817  \n",
       "2      /home/puneet/code/Multimodal Feedback/data/130...    1306  \n",
       "3      /home/puneet/code/Multimodal Feedback/data/651...    6514  \n",
       "4      /home/puneet/code/Multimodal Feedback/data/230...    2309  \n",
       "...                                                  ...     ...  \n",
       "58336  /home/puneet/code/Multimodal Feedback/data/669...    6697  \n",
       "58337  /home/puneet/code/Multimodal Feedback/data/541...    5417  \n",
       "58338  /home/puneet/code/Multimodal Feedback/data/627...    6271  \n",
       "58339  /home/puneet/code/Multimodal Feedback/data/935...    9358  \n",
       "58340  /home/puneet/code/Multimodal Feedback/data/622...    6220  \n",
       "\n",
       "[58341 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    \"\"\"\n",
    "    Tokenizes English text from a string into a list of strings (tokens)\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in nlp.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('src', <torchtext.data.field.Field at 0x7f17fbff7290>),\n",
       " ('trg', <torchtext.data.field.Field at 0x7f17fbff7310>),\n",
       " ('img_path', None),\n",
       " ('img_id', <torchtext.data.field.Field at 0x7f17fbff72d0>)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID = data.Field(sequential=False,use_vocab=False)\n",
    "SRC = Field(tokenize = tokenize_text, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True,\n",
    "            include_lengths = True)\n",
    "TRG = Field(tokenize = tokenize_text, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True,\n",
    "            )\n",
    "datafields=[('src', SRC), ('trg', TRG),('img_path',None),('img_id',ID)]\n",
    "datafields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "#rng = RandomState()\n",
    "#train_data = df.sample(frac=0.80, random_state=rng)\n",
    "#val_data = df.loc[~df.index.isin(train_data.index)]\n",
    "\n",
    "##cols= [\"src\", \"trg\", \"img_path\", \"img_id\"]\n",
    "#train_data.to_csv('train_data.csv', index= False) #columns=cols\n",
    "#val_data.to_csv('val_data.csv', index= False) #columns=cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = data.TabularDataset.splits(path=r\"\",train=\"train_data.csv\", validation=\"val_data.csv\", format='csv', skip_header=True, fields=datafields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_data))\n",
    "print(len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.maxsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_data, vectors=\"glove.6B.100d\")\n",
    "TRG.build_vocab(train_data, vectors=\"glove.6B.100d\")\n",
    "SRC.build_vocab(train_data, min_freq=2)\n",
    "TRG.build_vocab(train_data, min_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Unique tokens in target (en) vocabulary: {len(SRC.vocab)}\")\n",
    "print(f\"Unique tokens in target (en) vocabulary: {len(TRG.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4 #16\n",
    "\n",
    "train_iterator, x_iterator = BucketIterator.splits(\n",
    "    (train_data, train_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_within_batch = True,\n",
    "    sort_key = lambda x : len(x.src), \n",
    "    device = device)\n",
    "\n",
    "valid_iterator, y_iterator = BucketIterator.splits(\n",
    "    (val_data, val_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    sort_within_batch = True,\n",
    "    sort_key = lambda x : len(x.src),\n",
    "    device = device)\n",
    "\n",
    "#valid_iterator, y_iterator = BucketIterator.splits(\n",
    "#    (val_data, val_data), \n",
    "#    batch_size = BATCH_SIZE, \n",
    "#    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_iterator))\n",
    "print(len(valid_iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(valid_iterator):\n",
    "  print(i,batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hid_dim = hid_dim\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim) #no dropout as only one layer!\n",
    "        \n",
    "        self.rnn = nn.GRU(emb_dim, hid_dim)\n",
    "        \n",
    "        self.fc = nn.Linear(hid_dim * 2, hid_dim)\n",
    "        self.vis_fc=nn.Linear(NF, hid_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src, visual_features):\n",
    "        \n",
    "        vis_features= torch.tanh(self.vis_fc(visual_features))\n",
    "            \n",
    "        #src = [src len, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        \n",
    "        #embedded = [src len, batch size, emb dim]\n",
    "        \n",
    "        outputs, text_hidden = self.rnn(embedded) #no cell state!\n",
    "        \n",
    "        #outputs = [src len, batch size, hid dim * n directions]\n",
    "        #text_hidden = [n layers * n directions, batch size, hid dim]\n",
    "        vis_features=vis_features.unsqueeze(0)\n",
    "        hidden = torch.tanh(self.fc(torch.cat((text_hidden,vis_features), 2)))\n",
    "        \n",
    "        #outputs are always from the top hidden layer\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hid_dim = hid_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.GRU(emb_dim + hid_dim, hid_dim)\n",
    "        \n",
    "        self.fc_out = nn.Linear(emb_dim + hid_dim * 2, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, context):\n",
    "        \n",
    "        #input = [batch size]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #context = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #n layers and n directions in the decoder will both always be 1, therefore:\n",
    "        #hidden = [1, batch size, hid dim]\n",
    "        #context = [1, batch size, hid dim]\n",
    "        \n",
    "        input = input.unsqueeze(0)\n",
    "        \n",
    "        #input = [1, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        \n",
    "        #embedded = [1, batch size, emb dim]\n",
    "                \n",
    "        emb_con = torch.cat((embedded, context), dim = 2)\n",
    "            \n",
    "        #emb_con = [1, batch size, emb dim + hid dim]\n",
    "            \n",
    "        output, hidden = self.rnn(emb_con, hidden)\n",
    "        \n",
    "        #output = [seq len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #seq len, n layers and n directions will always be 1 in the decoder, therefore:\n",
    "        #output = [1, batch size, hid dim]\n",
    "        #hidden = [1, batch size, hid dim]\n",
    "        \n",
    "        output = torch.cat((embedded.squeeze(0), hidden.squeeze(0), context.squeeze(0)), \n",
    "                           dim = 1)\n",
    "        \n",
    "        #output = [batch size, emb dim + hid dim * 2]\n",
    "        \n",
    "        prediction = self.fc_out(output)\n",
    "        \n",
    "        #prediction = [batch size, output dim]\n",
    "        \n",
    "        return prediction, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
    "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        \n",
    "    def forward(self, src, visual_features, trg, teacher_forcing_ratio = 0.5):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        #trg = [trg len, batch size]\n",
    "        #teacher_forcing_ratio is probability to use teacher forcing\n",
    "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
    "        \n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        #last hidden state of the encoder is the context\n",
    "        context = self.encoder(src,visual_features)\n",
    "        \n",
    "        #context also used as the initial hidden state of the decoder\n",
    "        hidden = context\n",
    "        \n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        input = trg[0,:]\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            \n",
    "            #insert input token embedding, previous hidden state and the context state\n",
    "            #receive output tensor (predictions) and new hidden state\n",
    "            output, hidden = self.decoder(input, hidden, context)\n",
    "            \n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            \n",
    "            #decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            #get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1) \n",
    "            \n",
    "            #if teacher forcing, use actual next token as next input\n",
    "            #if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_HID_DIM = 125\n",
    "ENC_EMB_DIM = 64\n",
    "DEC_EMB_DIM = 64\n",
    "HID_DIM = 128\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, DEC_DROPOUT)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        src,src_len = batch.src\n",
    "        trg = batch.trg\n",
    "        img_id=batch.img_id\n",
    "        \n",
    "        x=img_id.cpu().numpy()\n",
    "        y=len(x)\n",
    "        #visual_features=torch.empty(y,4096).cuda()\n",
    "        visual_features=torch.empty(y,NF).cuda()\n",
    "        df=pd.read_csv(r\"visual_features_resnet.csv\")\n",
    "        for i in range(y):\n",
    "            q=df[str(x[i])].to_numpy()\n",
    "            a=torch.from_numpy(q).unsqueeze(0)\n",
    "            visual_features[i]=a\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src,visual_features, trg)\n",
    "        \n",
    "        #trg = [trg len, batch size]\n",
    "        #output = [trg len, batch size, output dim]\n",
    "        \n",
    "        output_dim = output.shape[-1]\n",
    "        \n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "        \n",
    "        #trg = [(trg len - 1) * batch size]\n",
    "        #output = [(trg len - 1) * batch size, output dim]\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            src,src_len = batch.src\n",
    "            trg = batch.trg\n",
    "            img_id=batch.img_id\n",
    "        \n",
    "            x=img_id.cpu().numpy()\n",
    "            y=len(x)\n",
    "            #visual_features=torch.empty(y,4096).cuda()\n",
    "            visual_features=torch.empty(y,NF).cuda()\n",
    "            df=pd.read_csv(r\"visual_features_resnet.csv\")\n",
    "            for i in range(y):\n",
    "                q=df[str(x[i])].to_numpy()\n",
    "                a=torch.from_numpy(q).unsqueeze(0)\n",
    "                visual_features[i]=a\n",
    "\n",
    "            output = model(src, visual_features, trg, 0) #turn off teacher forcing\n",
    "\n",
    "            #trg = [trg len, batch size]\n",
    "            #output = [trg len, batch size, output dim]\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            #trg = [(trg len - 1) * batch size]\n",
    "            #output = [(trg len - 1) * batch size, output dim]\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpt(model, optimizer, chpt_file):\n",
    "    start_epoch = 0\n",
    "    if (os.path.exists(chpt_file)):\n",
    "        print(\"=> loading checkpoint '{}'\".format(chpt_file))\n",
    "        checkpoint = torch.load(chpt_file)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        \n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\".format(chpt_file, checkpoint['epoch']))\n",
    "        \n",
    "    else:\n",
    "        print(\"=> Checkpoint NOT found '{}'\".format(chpt_file))\n",
    "    return model, optimizer, start_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(sentence, src_field, trg_field, img_id, path, model, device, max_len = 50):\n",
    "\n",
    "    model.eval()\n",
    "        \n",
    "    if isinstance(sentence, str):\n",
    "        nlp = spacy.load('en')\n",
    "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "\n",
    "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
    "        \n",
    "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
    "    \n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
    "\n",
    "    src_len = torch.LongTensor([len(src_indexes)]).to(device)\n",
    "    \n",
    "    df=pd.read_csv(path)\n",
    "    visual_features=torch.empty(1,NF).cuda()\n",
    "#    visual_features=torch.empty(1,4096).cuda()\n",
    "    q=df[str(img_id)].to_numpy()\n",
    "    a=torch.from_numpy(q).unsqueeze(0)\n",
    "    visual_features[0]=a\n",
    "\n",
    "    with torch.no_grad():\n",
    "        hidden = model.encoder(src_tensor,visual_features)#, src_len)\n",
    "        \n",
    "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
    "    \n",
    "    for i in range(max_len):\n",
    "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)          \n",
    "        with torch.no_grad():\n",
    "            output, hidden = model.decoder(trg_tensor, hidden, hidden)\n",
    "\n",
    "        pred_token = output.argmax(1).item()\n",
    "        \n",
    "        trg_indexes.append(pred_token)\n",
    "\n",
    "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
    "            break\n",
    "    \n",
    "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
    "    \n",
    "    return trg_tokens[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''text_idx = 25                #renamed from 'example_idx'\n",
    "image_idx=\"9\"\n",
    "\n",
    "path=r\"visual_features.csv\"\n",
    "\n",
    "src = vars(train_data.examples[text_idx])['src']\n",
    "trg = vars(train_data.examples[text_idx])['trg']\n",
    "#img = vars(train_data.examples[text_idx])['img_path']\n",
    "\n",
    "translation = translate_sentence(src, SRC, TRG, image_idx,path, model, device)\n",
    "\n",
    "#print(f'src = {src}\\n')\n",
    "print(f'Ground-truth Comment')\n",
    "print( '--------------------')\n",
    "print(f'trg = {trg}')\n",
    "\n",
    "print(f'\\n\\nPredicted Feedback (Feedback)')\n",
    "print( '-----------------------------')\n",
    "    \n",
    "print(f'{translation}')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Spice & Meteor\n",
    "#### (Hitting erorr in py3, need to run in py2...) tried switching the kernel to py2 and runnign here but T_EPOCHS is cleared off...\n",
    "#### 1. Go to '/home/puneet/code/EvalMetrics_py2'\n",
    "#### 2. Copy 'nEp_test_comments.csv' & 'nEp_test_feedbacks.csv'\n",
    "#### 3. Rename as 'test_comments.csv' & 'test_feedbacks.csv'\n",
    "#### 4. Run eval.py with 'py2' env\n",
    "#### 5. Rename the generated 'scores.txt' file  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quant_eval(model, optimizer, start_epoch, chpt_file):\n",
    "    from pycocoevalcap.bleu.bleu import Bleu\n",
    "    from pycocoevalcap.cider.cider import Cider\n",
    "    from pycocoevalcap.meteor.meteor import Meteor\n",
    "    from pycocoevalcap.rouge.rouge import Rouge\n",
    "    from pycocoevalcap.spice.spice import Spice\n",
    "    import os, json, csv\n",
    "    \n",
    "    model, optimizer, start_epoch = load_checkpt(model, optimizer, chpt_file)\n",
    "    T_EPOCHS = start_epoch + EP_INT    \n",
    "    \n",
    "\n",
    "    #print('Download Stanford models... Run once!')\n",
    "    os.system(\"sh get_stanford_models.sh\")\n",
    "\n",
    "    with open('temp/'+str(T_EPOCHS)+'Ep_test_comments.csv',\"r\") as f: \n",
    "            reader = csv.reader(f)\n",
    "            gts = {rows[0]:rows[1:] for rows in reader}\n",
    "            #print(mydict) #prints with single quotes\n",
    "            #print (json.dumps(mydict)) #prints with double quotes\n",
    "\n",
    "    with open('temp/'+str(T_EPOCHS)+'Ep_test_feedbacks.csv',\"r\") as g: \n",
    "            reader = csv.reader(g)\n",
    "            res = {rows[0]:rows[1:] for rows in reader}\n",
    "            #print(json.dumps(mydict))\n",
    "\n",
    "    '''with open('temp/test_comments.json', 'r') as file:\n",
    "        gts = json.load(file)\n",
    "    with open('temp/test_feedbacks.json', 'r') as file:\n",
    "        res = json.load(file)\n",
    "    '''\n",
    "\n",
    "    def bleu():\n",
    "        scorer = Bleu(n=4)\n",
    "        score, scores = scorer.compute_score(gts, res)\n",
    "        return score\n",
    "\n",
    "\n",
    "    def cider():\n",
    "        scorer = Cider()\n",
    "        (score, scores) = scorer.compute_score(gts, res)\n",
    "        return score\n",
    "\n",
    "    def rouge():\n",
    "        scorer = Rouge()\n",
    "        score, scores = scorer.compute_score(gts, res)\n",
    "        return score\n",
    "\n",
    "    #bgts = gts[0].encode(encoding='UTF-8')\n",
    "    #bres = res[0].encode(encoding='UTF-8')\n",
    "\n",
    "    def spice():\n",
    "        scorer = Spice()\n",
    "        #print(gts, res)\n",
    "        score, scores = scorer.compute_score(gts, res)\n",
    "        return score\n",
    "\n",
    "    def meteor():\n",
    "        scorer = Meteor()\n",
    "        #print(gts, res)\n",
    "        score, scores = scorer.compute_score(bgts, bres)\n",
    "        return score    \n",
    "    s_cider=cider()\n",
    "    s_rouge=rouge()\n",
    "    s_bleu=bleu()\n",
    "    #s_spice=spice()#\n",
    "    #s_meteor=meteor()#\n",
    "    \n",
    "    print('\\n----------------------\\nbleu = %s' %s_bleu )\n",
    "    print('cider = %s' %s_cider )\n",
    "    print('rouge = %s' %s_rouge )\n",
    "    #print('spice = %s' %s_spice )\n",
    "    #print('meteor = %s' %s_meteor )\n",
    "    \n",
    "    b=\" \".join(str(x) for x in s_bleu)\n",
    "    print('\\n----------------------')\n",
    "    f = open('scores.txt', 'w') \n",
    "    f.write(\"\\ncider: %f\" % s_cider)\n",
    "    f.write(\"\\nrouge: %f\" % s_rouge)\n",
    "    #f.write(\"\\nspice: %f\" % s_spice)\n",
    "    #f.write(\"\\nmeteor: %f\" % s_meteor)\n",
    "    f.write(\"\\nbleu :\")\n",
    "    f.write(b)\n",
    "    f.close()\n",
    "    \n",
    "    #print(str(T_EPOCHS))\n",
    "    #Log with Tensorboard: Eval metrics\n",
    "    log_writer.add_text(str(T_EPOCHS)+'Ep=>Metrics/cider', str(s_cider))\n",
    "    log_writer.add_text(str(T_EPOCHS)+'Ep=>Metrics/rouge', str(s_rouge))\n",
    "    #log_writer.add_text(str(T_EPOCHS)+'Ep=>Metrics/spice', str(s_spice))\n",
    "    #log_writer.add_text(str(T_EPOCHS)+'Ep=>Metrics/meteor', str(s_meteor))\n",
    "    log_writer.add_text(str(T_EPOCHS)+'Ep=>Metrics/bleu-1', str(s_bleu[0]))\n",
    "    log_writer.add_text(str(T_EPOCHS)+'Ep=>Metrics/bleu-2', str(s_bleu[1]))\n",
    "    log_writer.add_text(str(T_EPOCHS)+'Ep=>Metrics/bleu-3', str(s_bleu[2]))\n",
    "    log_writer.add_text(str(T_EPOCHS)+'Ep=>Metrics/bleu-4', str(s_bleu[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qual_eval(model, optimizer, start_epoch, chpt_file):\n",
    "    model, optimizer, start_epoch = load_checkpt(model, optimizer, chpt_file)\n",
    "    T_EPOCHS = start_epoch + EP_INT\n",
    "    \n",
    "    # Save the predicted Feedbacks in CSV file\n",
    "    # Log with Tensorboard: Text, Comment, Image and Feedback\n",
    "    test_pred=[]\n",
    "    #test_df=pd.read_csv(\"temp/test_data.csv\")  \n",
    "    test_df=pd.read_csv(\"temp/test_data1.csv\") \n",
    "    path=r\"visual_features_resnet.csv\"      \n",
    "    length=test_df.shape[0]\n",
    "    images = []\n",
    "\n",
    "    #print(length)\n",
    "    for i in range(length):\n",
    "        src=test_df['src'][i]\n",
    "        trg=test_df['trg'][i]\n",
    "        img_path=test_df['img_path'][i]\n",
    "        image_idx=test_df['img_id'][i]\n",
    "        translation, attention = translate_sentence(src, SRC, TRG, image_idx, path, model, device)\n",
    "\n",
    "        if not translation:\n",
    "            translation=\"*empty*\"\n",
    "\n",
    "        #Untokenization    \n",
    "        translation1=translation[0:(len(translation)-1)]    \n",
    "        translation2 = TreebankWordDetokenizer().detokenize(translation1)\n",
    "        test_pred.append(str(translation2))\n",
    "\n",
    "        image = Image.open(img_path)\n",
    "        image = ToTensor()(image)   \n",
    "        #images.append(image)\n",
    "        \n",
    "        #print(str(T_EPOCHS))\n",
    "        if (i%10==0): \n",
    "            #Log with Tensorboard: Text, Comment, Image and Feedback\n",
    "            log_writer.add_text(str(T_EPOCHS)+'Ep=>Ground-truth Comment of Sample/'+str(i+1), str(trg))\n",
    "            log_writer.add_text(str(T_EPOCHS)+'Ep=>News Text of Sample/'+str(i+1), str(src))#, i+1)\n",
    "            log_writer.add_text(str(T_EPOCHS)+'Ep=>Predicted Feedback of Sample/'+str(i+1), str(translation))\n",
    "            #log_writer.add_image('Image', image, i+1)\n",
    "            #image_grid = torchvision.utils.make_grid(images)\n",
    "            log_writer.add_image(str(T_EPOCHS)+'Ep:Image of Sample/'+str(i+1), image)        \n",
    "\n",
    "    with open('temp/'+str(T_EPOCHS)+'Ep_test_results.csv', 'w'): \n",
    "        pass\n",
    "    with open('temp/'+str(T_EPOCHS)+'Ep_test_comments.csv', 'w'): \n",
    "        pass\n",
    "    with open('temp/'+str(T_EPOCHS)+'Ep_test_feedbacks.csv', 'w'): \n",
    "        pass\n",
    "\n",
    "    test_df[\"pred\"] = test_pred \n",
    "    test_df.to_csv('temp/'+str(T_EPOCHS)+'Ep_test_results.csv', index= False)\n",
    "    test_df.to_csv('temp/'+str(T_EPOCHS)+'Ep_test_comments.csv', index= True, columns=[\"trg\"]) #index -> \"key\": value -> [\"trg/pred\"]\n",
    "    test_df.to_csv('temp/'+str(T_EPOCHS)+'Ep_test_feedbacks.csv', index= True, columns=[\"pred\"])\n",
    "\n",
    "    #Re-open and save with new column names\n",
    "    df = pd.read_csv('temp/'+str(T_EPOCHS)+'Ep_test_comments.csv')\n",
    "    df.columns = ['id', 'comment']\n",
    "    df.to_csv('temp/'+str(T_EPOCHS)+'Ep_test_comments.csv', index= False)\n",
    "\n",
    "    df = pd.read_csv('temp/'+str(T_EPOCHS)+'Ep_test_feedbacks.csv')\n",
    "    df.columns = ['id', 'feedback']\n",
    "    df.to_csv('temp/'+str(T_EPOCHS)+'Ep_test_feedbacks.csv', index= False)\n",
    "    \n",
    "    print('tensorboard --logdir \"/home/puneet/code/Multimodal Feedback/TBlogs\"\\n---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interval_train(model, optimizer, start_epoch, chpt_file):\n",
    "    model, optimizer, start_epoch = load_checkpt(model, optimizer, chpt_file)\n",
    "    T_EPOCHS = start_epoch + EP_INT\n",
    "\n",
    "    print('Already trained for',start_epoch, 'epochs. Training now for', EP_INT, 'more')\n",
    "\n",
    "    best_valid_loss = float('inf')\n",
    "    cur_best_train_loss = float('inf')\n",
    "\n",
    "    #for epoch in range(EP_INT):\n",
    "    for epoch in range(start_epoch, T_EPOCHS):    \n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss = train(model, train_iterator, optimizer, criterion, CLIP)#, log_writer_train)\n",
    "        valid_loss = evaluate(model, valid_iterator, criterion)#, log_writer_val)\n",
    "\n",
    "        #Log with Tensorboard: Loss & PPL for train & val \n",
    "        log_writer.add_scalar('Train/Loss',float(train_loss), epoch+1)\n",
    "        log_writer.add_scalar('Train/PPL', float(math.exp(train_loss)), epoch+1)    \n",
    "        log_writer.add_scalar('Val/Loss',float(valid_loss), epoch+1)\n",
    "        log_writer.add_scalar('Val/PPL', float(math.exp(valid_loss)), epoch+1)\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        #if valid_loss < best_valid_loss:\n",
    "        #    best_valid_loss = valid_loss\n",
    "        #if train_loss < cur_best_train_loss:\n",
    "        #    cur_best_train_loss = train_loss\n",
    "\n",
    "        state = {'epoch': T_EPOCHS, 'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict(), 'loss': train_loss}\n",
    "        torch.save(state, chpt_file)\n",
    "\n",
    "        print(f'\\nEpoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
    "\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chpt_file = '/home/puneet/code/Multimodal Feedback/checkpoints/baseline1.pt'\n",
    "model, optimizer, start_epoch = load_checkpt(model, optimizer, chpt_file)\n",
    "T_EPOCHS = start_epoch + EP_INT\n",
    "    \n",
    "for i in range(EPOCHS):\n",
    "    if (i%EP_INT==0):\n",
    "        interval_train(model, optimizer, start_epoch, chpt_file)\n",
    "        print('\\nEvaluation\\n----------------------')\n",
    "        qual_eval(model, optimizer, start_epoch, chpt_file)\n",
    "        quant_eval(model, optimizer, start_epoch, chpt_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
